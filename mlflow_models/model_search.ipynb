{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from train_rf import CATEGORICAL_FEATURES, NUMERICAL_FEATURES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment=dict(mlflow.get_experiment_by_name(\"loan\"))\n",
    "experiment_id=current_experiment['experiment_id']\n",
    "\n",
    "# Get this from UI or CLI\n",
    "rf_parent_run = \"03046a89d08346a5bda301cc7c745885\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment had 10 HP tuning round\n",
      "Best run - 0 with PR AUC of 0.104\n"
     ]
    }
   ],
   "source": [
    "# To access MLFlow stuff we need to work with MlflowClient\n",
    "client = MlflowClient()\n",
    "\n",
    "# Searches runs for a specific attribute and filters them by Parent Run ID\n",
    "runs = client.search_runs(\n",
    "    [experiment_id], \n",
    "    f\"tags.mlflow.parentRunId = '{rf_parent_run}'\", \n",
    "    order_by=[\"metrics.test_PR_AUC DESC\"]\n",
    ")\n",
    "\n",
    "# Select the best run according to test_PR_AUC metric\n",
    "best_run = np.argmax([f.data.metrics['test_PR_AUC'] for f in runs])\n",
    "best_pr_auc = np.round(runs[best_run].data.metrics['test_PR_AUC'], 4)\n",
    "\n",
    "print(f\"Experiment had {len(runs)} HP tuning round\")\n",
    "print(f\"Best run - {best_run} with PR AUC of {best_pr_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model URI - runs:/1d2537d89cb04760b3b9bc501ee0854f/sklearn_models\n"
     ]
    }
   ],
   "source": [
    "# log-model history is stored as string, so we need to \"jsonify\" it first\n",
    "log_model_info = json.loads(runs[best_run].data.tags['mlflow.log-model.history'])[0]\n",
    "\n",
    "# Construct a valid model URI\n",
    "model_uri = 'runs:/' + log_model_info['run_id'] + '/' + log_model_info['artifact_path']\n",
    "print(f\"Best model URI - {model_uri}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sample to test the model\n",
    "data = pd.read_csv(\"./data/raw/train.csv\", nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/14 11:46:29 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - category-encoders (current: 2.6.0, required: category-encoders==2.3.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4980769, 0.5019231]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model as pyfunc\n",
    "sklearn_pyfunc = mlflow.pyfunc.load_model(model_uri=model_uri)\n",
    "sklearn_pyfunc.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register and Promote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'loan_model'.\n",
      "2023/02/14 11:51:20 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: loan_model, version 1\n",
      "Created version '1' of model 'loan_model'.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'loan_model'\n",
    "model_version = 1\n",
    "\n",
    "# Register model\n",
    "mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "# Promote to Production\n",
    "logs = client.transition_model_version_stage(name=model_name, version=model_version, stage=\"Production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from Production Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/02/14 11:54:25 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - category-encoders (current: 2.6.0, required: category-encoders==2.3.0)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.4980769, 0.5019231]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage = 'Production'\n",
    "\n",
    "# Since it's a registered model in Production, we can load it like this now!\n",
    "# No need for model URIs\n",
    "model_registry_path = f'models:/{model_name}/{stage}'\n",
    "production_model = mlflow.pyfunc.load_model(model_registry_path)\n",
    "\n",
    "production_model.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command in the terminal: `mlflow models serve --model-uri models:/loan_model/Production -p 5001`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call from server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data to be sent to API\n",
    "example = data[NUMERICAL_FEATURES + CATEGORICAL_FEATURES]\n",
    "to_send = example.to_dict(orient='split')\n",
    "to_send.pop(\"index\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction endpoint\n",
    "url = 'http://127.0.0.1:5001/invocations'\n",
    "\n",
    "# Preprocess the example\n",
    "response = requests.post(url=url, data=json.dumps({\"dataframe_split\" :to_send}), headers={\"Content-type\": \"application/json\"})\n",
    "\n",
    "# Load the response\n",
    "response_json = json.loads(response.text)\n",
    "print(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2df742b932880654a3f6652148a9c802dc0dfad475f6beda4797814052023f2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
